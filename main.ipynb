{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pytesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'E:\\\\TesseractOCR\\\\tesseract.exe'\n",
    "from pytesseract import Output \n",
    "\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader: \n",
    "To load train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOCRDataset (Dataset):\n",
    "    def __init__(self, image_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "\n",
    "        #Transformations done post tesseract processing\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.image_paths[index]\n",
    "\n",
    "        #Load image as PIL and ensure RGB format\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        #Add resizing and other preprocesssing as needed below\n",
    "        # -\n",
    "        # -\n",
    "        # -\n",
    "\n",
    "        return image\n",
    "    \n",
    "    def __len__(self):\n",
    "        #count of images\n",
    "        return len(self.image_paths)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset Paths\n",
    "image_paths = []\n",
    "SignverOD_path = \"E:\\\\PROJECTS\\\\Personal Projects\\\\AI-Powered-Contract-Auditing-System\\\\Datasets\\\\SignverOD\\\\images\"  \n",
    "image_paths.append(SignverOD_path)   #SignverOD Dataset (Physical Signatures)\n",
    "\n",
    "#Activating dataset processing\n",
    "#dataset = CustomOCRDataset(image_path, transform=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgToTxt(img):\n",
    "    #<--This function extracts text data from an image-->\n",
    "\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    return text\n",
    "\n",
    "def getGrayScale(img):\n",
    "    #<--This function converts image into grayscale in order to make text clearer-->\n",
    "\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def removeNoise(img):\n",
    "    #<--This fucntion removes any blurr from the image--> \n",
    "\n",
    "    return cv2.medianBlur(img,5)\n",
    "\n",
    "def thresholding(img):\n",
    "    #<--This function makes the image pure black and white, making it easier for pytesseract to extract text\n",
    "\n",
    "    return cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "def resizeImg(img):\n",
    "    #<--This function resizes the image to 128 x 128-->\n",
    "\n",
    "    return cv2.resize(img, (128, 128))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImagesFromFolder(path=None):\n",
    "    #<---This function reads all image files from a specific folder-->\n",
    "    #path :- stored path to the images\n",
    "\n",
    "    images = [] #Stores all read images\n",
    "    allowed_extensions = ['.png', '.jpg', '.jpeg']  # List of allowed image extensions\n",
    "\n",
    "    #Go thorugh the specified folder and store all image files\n",
    "    try:\n",
    "        for filename in os.listdir(path):\n",
    "            path = os.path.join(path, filename)\n",
    "\n",
    "            if os.path.isfile(path):\n",
    "                try:\n",
    "                    _, extension = os.path.splitext(filename)\n",
    "                    #Allow only the valid extensions for image files\n",
    "                    if extension.lower() in allowed_extensions:\n",
    "                        img = cv2.imread(path)\n",
    "\n",
    "                        #check if its a valid image\n",
    "                        if img is not None and (img.ndim == 2 or img.ndim == 3): \n",
    "                            images.append(img)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(\"Error reading file: {filename} - {e}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found in folder {path}\")\n",
    "    except NotADirectoryError:\n",
    "        print(\"Invalid directory {path}\")\n",
    "    \n",
    "    return images\n",
    "\n",
    "path = \"E:\\\\PROJECTS\\\\Personal Projects\\\\AI-Powered-Contract-Auditing-System\\\\Datasets\"\n",
    "image_files = readImagesFromFolder(path)\n",
    "print(len(image_files))\n",
    "\n",
    "\n",
    "for img in image_files:\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    img = getGrayScale(img)\n",
    "    img = thresholding(img)\n",
    "    img = removeNoise(img)\n",
    "    print(imgToTxt(img))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Localisation and Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "results = pytesseract.image_to_data(rgb, output_type=Output.DICT)\n",
    "\n",
    "print(results.keys())\n",
    "\n",
    "\n",
    "\n",
    "n_boxes = len(results['text'])\n",
    "for i in range(n_boxes):\n",
    "    if int(results['conf'][i]) > 60:  # You can adjust the confidence threshold\n",
    "        (x, y, w, h) = (results['left'][i], results['top'][i], results['width'][i], results['height'][i])\n",
    "        text = results['text'][i]\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Draw a green rectangle\n",
    "        cv2.putText(img, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "#cv2.imshow(\"Text Detection\", img)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures(image):\n",
    "    \"\"\"\n",
    "    Features Used\n",
    "        Pixel Intensity: Analyze pixel values to identify signature patterns.\n",
    "        Edge Detection: Use techniques like the Sobel operator to detect signature edges.\n",
    "        HOG (Histogram of Oriented Gradients): Capture the shape and texture of the signature.\n",
    "    \"\"\"\n",
    "    features, _ = hog(image, orientations=9, pixels_per_cell=(8, 8), \n",
    "                      cells_per_block=(2, 2), block_norm='L2-Hys', visualize=True)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Setup and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "#Train SVM model\n",
    "model = SVC(kernel='linear', probability=True)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the modelâ€™s performance\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
